--- Búsqueda de Hiperparámetros Completada ---
Mejores hiperparámetros encontrados: {'classifier__colsample_bytree': 1.0, 'classifier__gamma': 0.2, 'classifier__learning_rate': 0.2, 'classifier__max_depth': 9, 'classifier__n_estimators': 100, 'classifier__subsample': 0.9}
Mejor score de AUC-ROC en validación cruzada: 0.5187

## 3. Evaluación del Modelo XGBoost Optimizado (Umbral Por Defecto)


--- Reporte de Clasificación (XGBoost Optimizado - Umbral Por Defecto) ---
              precision    recall  f1-score   support

       Falla       0.80      0.87      0.83       807
       Éxito       0.16      0.11      0.13       193

    accuracy                           0.72      1000
   macro avg       0.48      0.49      0.48      1000
weighted avg       0.68      0.72      0.70      1000


--- Matriz de Confusión (XGBoost Optimizado - Umbral Por Defecto) ---

--- AUC-ROC (XGBoost Optimizado - Umbral Por Defecto): 0.4787 ---


--- Verificación de Clases Reales en y_test ---
IsSuccess
0    807
1    193
Name: count, dtype: int64

--- Verificación de Clases Predichas por el Modelo Optimizado (Umbral Por Defecto) ---
0    872
1    128
Name: count, dtype: int64

--- Distribución de Probabilidades Predichas para la clase 'Éxito' ---
0     0.782605
1     0.233484
2     0.018187
3     0.081457
4     0.017822
5     0.158108
6     0.009645
7     0.133977
8     0.567704
9     0.046202
10    0.006933
11    0.581977
12    0.533711
13    0.020029
14    0.023401
15    0.030375
16    0.756777
17    0.041535
18    0.298226
19    0.100244
dtype: float32
Probabilidad mínima predicha para 'Éxito': 0.0002
Probabilidad máxima predicha para 'Éxito': 0.9774
Probabilidad promedio predicha para 'Éxito': 0.2083

## 4. Ajuste del Umbral de Clasificación para la Clase 'Éxito'

Buscando el umbral óptimo para maximizar el F1-score de la clase 'Éxito'...
C:\Users\Víctor\Documents\paint_predictor_mvp\scripts\modeling\paint_formula_xgboost_modeling.py:122: RuntimeWarning: invalid value encountered in divide
  f1_scores = (2 * precisions * recalls) / (precisions + recalls)
Mejor F1-score para la clase 'Éxito': 0.3244 en el umbral: 0.0021

--- Reporte de Clasificación (XGBoost Optimizado - Umbral Ajustado a 0.0021) ---
              precision    recall  f1-score   support

       Falla       1.00      0.00      0.01       807
       Éxito       0.19      1.00      0.32       193

    accuracy                           0.20      1000
   macro avg       0.60      0.50      0.17      1000
weighted avg       0.84      0.20      0.07      1000


--- Matriz de Confusión (XGBoost Optimizado - Umbral Ajustado a 0.0021) ---

## 5. Importancia de Características (XGBoost Optimizado)